
Statistical D1a Failure Analysis via Natural Language Processing: Topic Modeling and Social Network Analysis

Manho Hong1, Weonseog Nam1 , Cheol-hoon Son1, Yonghwan Cho1,

(Abstract) 
A large amount of high frequency test data is extensively generated by the advancement of DRAM fabrication and test methodology. Development of failure analysis model and its statistical inference are as important as the rapid progress on the DRAM technology. In this work we consider Natural Language Processing with No Rejection Test data. We identified 8 key failure factors of D1a DRAM, and improved high frequency test yield from 70.1% to 94.3% by optimizing fuse condition through Social Network Analysis for each factor.

Keywords : Natural Language Processing, Topic Modeling, Social Network Analysis, High Frequency Test, No Rejection Test

1. INTRODUCTION
Mobile DRAM, LPDDR performs various tests such as DC, MBT, LFT, and HFT to guarantee quality before selling to customers. In particular, HFT refers to the process of testing high-frequency DDR functions in an environment which the user actually uses DRAM. Moreover, HFT has the feature to generate NRT(No Rejection Test) data that records all failure histories among thousands of test items. Multidimensional analysis is required to effectively utilize NRT, but it is currently used in a limited way to preemptively respond to test items with a high failure rate. Thus, we consider NLP(Natural Language Processing), a statistical analysis methodology, within NRT data to efficiently identify key failure factors and find optimized fuse condition. 
 
Fig. 1. Example data of NRT

2. METHODOLOGY
2-1. NATURAL LANGUAGE PROCESSING
Natural language processing (NLP) refers to the branch of data science concerned with giving computers the ability to understand text and spoken words in much the same way human beings can. It utilizes for a variety of purposes such as sentiment analysis, text or speech summarization. In this work, we consider Latent Dirichlet Allocation(LDA, Topic Modeling) and Social Network Analysis(SNA) to identify key failure factors of D1a DRAM and interpret the relationship between test items.

2-2. LATNET DIRICHLET ALLOCATION  ( LDA, TOPIC MODELING ) 
 
 
Fig. 2. Formula of LDA
In Fig. 2, the only variable we can observe is Wd,n, which means the nth word(failure test item) in the dth document(DRAM device). Therefore, it is necessary to estimate all latent variables except the hyper-parameter which are alpha of the Dirichlet distribution and the number of topics K. Finally, we would find z, phi and theta that maximize the posterior probability in the above formula through Gibbs sampling.

2-3. SOCIAL NETWORK ANALYSIS

Fig. 3. Simple network example

Social network analysis aims to discover important test items for each topic by analyzing betweenness of nodes(failure test item). Fig. 3 shows two cases in which node A’s betweenness are 1 and 0, respectively. To verify the importance of node, we calculate how much A goes through when it moves to another node. In case 1, the shortest paths from node X to Y always pass through A, and the betweenness is 1. Conversely in case 2, the shortest paths from node X to Y never pass through A, the betweenness is 0. Therefore, in order to find the optimized fuse condition, it is necessary to find test items with high betweenness for each topic.

3. RESULT
 
Fig. 4. Perplexity and coherence for each number of topics (k)

Fig. 4 shows the Perplexity and Coherence index by each number of topics. The larger value of Perplexity, meaning independence between each topic, and the smaller value of Coherence, meaning unity within each topic, means better model performance. Thus, the number of topics whose performance does not improve even if the number of topics increases is set to 8, and the parameter of the Dirichlet distribution alpha, is set to 6.25.

 
Fig. 5. Intertopic distance map

Fig. 5 is intertopic distance map that shows each topic in the coordinate plane of two principle components. Most topics are located independently, but since 7.5Gbps LVDD and tAA Slow are similar types, it can be confirmed that there is an overlapping area. For comparison, we considered another model with LP4 NU-ver that has stabilized fabrication. Finally, we proved the validity of the analysis by finding the current failure caused by tPD fast of wafer edge which is chronic failure of NU-ver.

 
Fig. 6. Result of Latent Dirichlet Allocation

Fig. 6 shows top 6 test items which have highest appearance probability for each topic. Through the interpretation of items, all topics were named as “500Mbps”, “DVFSC tOC”, “LPDDR5 T/C”, “IBIS”, “7500Mbps tAA Slow”, “Self Refresh”, “6400Mbps AC” and “Write CSL”. Further analysis was not conducted for “500Mbps” and “IBIS” because it caused by environmental factors. Finally, the key failure factors of D1a LP5 WH-ver would be summarized as LVDD poor margin caused by tAA Slow and far bank Write CSL & PDL.

 
Fig. 7. Result of Social Network Analysis

Fig. 7 shows top 3 items which have highest betweennees for each topic. First, in “DVFSC tOC”, the “DCM” and “DWNN” has the highest value. These are the item in DVFSC mode which using VDD2L, and tOC timing adjustment is required to improve this failure. Next is “LPDDR5 T/C”, “NV5” has the highest value. This is an item to prevent the claim from NVIDIA, and is characterized by performing various data and address operations. In order to improve this failure, DINPAR margin must be secured. Next is “7500Mbps tAA Slow” and “6400Mbps AC”, and items with perform RMW(Read Modified Write) operation at high speed have highest values. Faster tPD targeting is needed to improve this failure. Next is “Self Refresh”, and items that perform self-refresh operations in the Power Down Mode and Deep Sleep Mode have highest values. Finally, in “Write CSL”, the “GLYA” that performs Gapless BL32 write operation has a high value. To solve this problem, it is necessary to adjust the Write CSL timing. Therefore, the optimized fuse condition was determined as follows.

 
Fig. 8. Optimized fuse condition

Figure 8 is the optimized fuse condition discovered through the analysis so far. As mentioned earlier, DINPAR, Write CSL, and PDL Timing were adjusted, and LIO Margin was additionally secured to prevent side effects. After applying this fuse condition, the HFT yield improved from 70.1% to 94.3%.

4. CONCLUSION
In this study, 8 key failure factors of D1a DRAM were identified by applying natural language processing within NRT data, and optimized fuse conditions were found to improve HFT yield from 70.1% to 94.3%. This methodology not only improves work efficiency for beginners but also helps to reduce trial and error in the early stages of product development. Furthermore, it is possible to develop an advanced test methodology by applying it to various test processes such as MBT and LFT.



















REFERENCES 
[1] Latent dirichlet allocation, The Journal of Machine Learning, Research Volume 33/1/2003 p. 993–1022

